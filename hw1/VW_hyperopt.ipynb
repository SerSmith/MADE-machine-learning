{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель:\n",
    "\n",
    "\n",
    "Скрипт, строящий vowpal wabbit модели для классификации текстов /n\n",
    "И подготавливающий результаты для сабмита в\n",
    "\n",
    "\n",
    "https://www.kaggle.com/c/made-ml-2019-hw1/overview\n",
    "\n",
    "\n",
    "Дата:\n",
    "\n",
    "\n",
    "29.10.2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vowpalwabbit import pyvw\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "from random import randrange\n",
    "import numpy as np\n",
    "from gensim.parsing import preprocessing as prep\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>assessment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2 . take around 10,000 640x480 pictures .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>the wrt54g plus the hga7t is a perfect solutio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>i dont especially like how music files are uns...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>i was using the cheapie pail ... and it worked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  assessment\n",
       "0          2 . take around 10,000 640x480 pictures .           1\n",
       "1  i downloaded a trial version of computer assoc...           1\n",
       "2  the wrt54g plus the hga7t is a perfect solutio...           1\n",
       "3  i dont especially like how music files are uns...           0\n",
       "4  i was using the cheapie pail ... and it worked...           1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('products_sentiment_train.tsv', sep='\\t', header = None)\n",
    "df_train.columns = [\"text\", \"assessment\"]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Уберем слова, которые встречаются реже, чем 2 раза\n",
    "class FilterRareWords(object):\n",
    "    def __init__(self):\n",
    "        self.cv = defaultdict(int)\n",
    "    def fit(self, texts):\n",
    "        for text in texts:\n",
    "            for word in text.split():\n",
    "                self.cv[word] += 1\n",
    "    def __call__(self, text):\n",
    "        return ' '.join([self.filter_word(word) for word in text.split()])\n",
    "    def filter_word(self, word):\n",
    "        return '' if self.cv[word] < 2 else word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_words = FilterRareWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, y_train = df_train.text, df_train.assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_words.fit(data_train)\n",
    "data_train = data_train.apply(filter_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, train_labels, valid_labels  =   train_test_split(data_train, y_train, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных для vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vw_format(document, label=None):\n",
    "#     Функция, переводящая данные в формат пригодный для vw\n",
    "#     document - текст\n",
    "#     label - target\n",
    "    num_w=len(document.split(\" \"))\n",
    "    delete_space = re.compile(\"[.;:!\\',\\\"()\\[\\]]\")\n",
    "    return str(label or '') + ' |text ' + \" \".join([ word for word in delete_space.sub(\"\",  document.lower()).split(\" \")]) +' |meta ' + 'num_sym:'+str(len(document))+' num_words:'+str(num_w)+' '+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples = []\n",
    "for text, target in zip(train, train_labels):\n",
    "    training_samples.append(to_vw_format(str(text), 1 if target == 1 else -1)[:-2])\n",
    "    \n",
    "test_samples = []\n",
    "for text, target in zip(valid, valid_labels):\n",
    "    test_samples.append(to_vw_format(str(text), 1 if target == 1 else -1)[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Моделька"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Игры с hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': 26, 'l1': 2e-06, 'l2': 1.2e-05, 'learning_rate': 0.3, 'link': 'logistic', 'loss_function': 'logistic', 'ngram': 2, 'skips': 2}\n",
      "0.4774645274720511                                                                                                     \n",
      "{'b': 24, 'l1': 2.6e-05, 'l2': 1.4999999999999999e-05, 'learning_rate': 0.3, 'link': 'logistic', 'loss_function': 'logistic', 'ngram': 2, 'skips': 2}\n",
      "0.47809636315658627                                                                                                    \n",
      "{'b': 23, 'l1': 1.3e-05, 'l2': 3e-06, 'learning_rate': 0.3, 'link': 'logistic', 'loss_function': 'logistic', 'ngram': 2, 'skips': 2}\n",
      "0.47071889722688437                                                                                                    \n",
      "{'b': 22, 'l1': 2.6e-05, 'l2': 6e-06, 'learning_rate': 0.3, 'link': 'logistic', 'loss_function': 'logistic', 'ngram': 1, 'skips': 2}\n",
      "0.4786642388354557                                                                                                     \n",
      "{'b': 26, 'l1': 1.4999999999999999e-05, 'l2': 2.2e-05, 'learning_rate': 0.3, 'link': 'logistic', 'loss_function': 'logistic', 'ngram': 1, 'skips': 2}\n",
      "0.47307449404360274                                                                                                    \n",
      "{'b': 26, 'l1': 2.2e-05, 'l2': 1.9999999999999998e-05, 'learning_rate': 0.3, 'link': 'logistic', 'loss_function': 'logistic', 'ngram': 2, 'skips': 2}\n",
      "0.4751652422397107                                                                                                     \n",
      "{'b': 25, 'l1': 4e-06, 'l2': 1.4e-05, 'learning_rate': 0.3, 'link': 'logistic', 'loss_function': 'logistic', 'ngram': 1, 'skips': 1}\n",
      "0.47753139976442904                                                                                                    \n",
      "{'b': 23, 'l1': 6e-06, 'l2': 2.4e-05, 'learning_rate': 0.3, 'link': 'logistic', 'loss_function': 'logistic', 'ngram': 1, 'skips': 2}\n",
      "0.4843332772792768                                                                                                     \n",
      "{'b': 23, 'l1': 4.9999999999999996e-06, 'l2': 7e-06, 'learning_rate': 0.3, 'link': 'logistic', 'loss_function': 'logistic', 'ngram': 2, 'skips': 1}\n",
      "0.46306051079057103                                                                                                    \n",
      "{'b': 23, 'l1': 1.8999999999999998e-05, 'l2': 7e-06, 'learning_rate': 0.3, 'link': 'logistic', 'loss_function': 'logistic', 'ngram': 1, 'skips': 1}\n",
      "0.4812430919982867                                                                                                     \n",
      "100%|██████████████████████████████████████████████████| 10/10 [01:47<00:00, 11.78s/it, best loss: 0.46306051079057103]\n"
     ]
    }
   ],
   "source": [
    "def hyperopt_vw(params):\n",
    "# Функция, для оценки качества модели в хиперопте\n",
    "    scores=[]\n",
    "    folds_quant=5\n",
    "    msk= [randrange(folds_quant) for p in range(len(training_samples))] \n",
    "\n",
    "    for i in range(folds_quant):\n",
    "#           Ручками посчитаем кроссвалидацию на folds_quant фолдов\n",
    "        model = pyvw.vw(\n",
    "            **params\n",
    "        )\n",
    "        train=np.array(training_samples)[list(np.array(msk) != i)]\n",
    "        test=np.array(training_samples)[list(np.array(msk) == i)]\n",
    "        test_labels=np.array(train_labels)[list(np.array(msk) == i)]\n",
    "\n",
    "        for iteration in range(25):\n",
    "            for k in range(len(train)):\n",
    "                model.learn(train[k])\n",
    "        \n",
    "        test_predictions = [model.predict(sample) for sample in test]\n",
    "  \n",
    "#        print(test_predictions)\n",
    "        scores.append(log_loss(test_labels, test_predictions))\n",
    "        \n",
    "        model.finish()\n",
    "\n",
    "    print(params)\n",
    "    print(np.array(scores).mean())\n",
    "    return  np.array(scores).mean()\n",
    "\n",
    "param_grid = { \n",
    "\"ngram\" : hp.choice('ngram', range(1, 3)),\n",
    "\"skips\" : hp.choice('skips', range(1, 3)),\n",
    "\"l1\" :  hp.quniform('l1', 0.000001, 0.00003, 0.000001),\n",
    "\"l2\" : hp.quniform('l2', 0.000001, 0.00003, 0.000001),\n",
    "\"b\" : hp.choice('b', range(22, 27)),\n",
    "\"learning_rate\" : 0.3,\n",
    "\"link\": 'logistic',\n",
    "\"loss_function\" : 'logistic'\n",
    "# \"bootstrap\" : hp.choice('bootstrap', range(0, 40,10))\n",
    "# \"hash\": 'all'\n",
    "}\n",
    "                  \n",
    "best_params = fmin(fn=hyperopt_vw, space=param_grid, algo=tpe.suggest, max_evals=10,verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 1, 'l1': 4.9999999999999996e-06, 'l2': 7e-06, 'ngram': 1, 'skips': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно заметить, что hp.choice возвращает не лучшее значение, а его id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение и праверка на валидационой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== step 0 ==========\n",
      "train LogLoss:  0.6931471805599452\n",
      "test LogLoss:  0.6931471805599452\n",
      "========== step 10 ==========\n",
      "train LogLoss:  0.1072883712939382\n",
      "test LogLoss:  0.46118086761387417\n",
      "========== step 20 ==========\n",
      "train LogLoss:  0.08538240442453962\n",
      "test LogLoss:  0.4568272036228802\n",
      "========== step 30 ==========\n",
      "train LogLoss:  0.07803716815071017\n",
      "test LogLoss:  0.45516854161199943\n",
      "========== step 40 ==========\n",
      "train LogLoss:  0.07457112156337303\n",
      "test LogLoss:  0.4548718598721998\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vw = pyvw.vw( \n",
    "    loss_function='logistic',\n",
    "\n",
    "    link='logistic',\n",
    "    b=22,\n",
    "#     bootstrap=20,\n",
    "    q='aa',\n",
    "#     cubic='aaa',\n",
    "    ngram=2,\n",
    "#     skips=1,\n",
    "#     hash='all',\n",
    "#     hessian_on=True,\n",
    "#     random_seed=112,\n",
    "    l1=0.00001,\n",
    "    l2=0.00001,\n",
    "    f='vw.log.model',\n",
    "    learning_rate=0.4)\n",
    "\n",
    "for iteration in range(50):\n",
    "    if iteration % 10 ==0:\n",
    "        train_predictions = [vw.predict(sample) for sample in training_samples]\n",
    "        test_predictions = [vw.predict(sample) for sample in test_samples]\n",
    "        print(\"========== step {0} ==========\".format(iteration))\n",
    "        print(\"train LogLoss: \",log_loss(train_labels, train_predictions))\n",
    "        print(\"test LogLoss: \",log_loss(valid_labels, test_predictions))\n",
    "    for i in range(len(training_samples)):\n",
    "            vw.learn(training_samples[i])\n",
    "vw.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более подробно можно посмотреть в \n",
    "https://www.analyticsvidhya.com/blog/2018/01/online-learning-guide-text-classification-vowpal-wabbit-vw/ https://github.com/VowpalWabbit/vowpal_wabbit/blob/master/python/examples/poisson_regression.ipynb https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Command-line-arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучимся всей выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея - модель не стабильная  так как мало наблюдений дававйте повысим стабильность убычившись на кроссвалидации и усреднив результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_full = []\n",
    "for text, target in zip(data_train, y_train):\n",
    "    training_full.append(to_vw_format(str(text), 1 if target == 1 else -1)[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== step 0 itteration 0 ==========\n",
      "train LogLoss:  0.6931471805599454\n",
      "========== step 5 itteration 0 ==========\n",
      "train LogLoss:  0.18797120127096517\n",
      "========== step 10 itteration 0 ==========\n",
      "train LogLoss:  0.16518528449395437\n",
      "========== step 15 itteration 0 ==========\n",
      "train LogLoss:  0.15738978457719702\n",
      "========== step 20 itteration 0 ==========\n",
      "train LogLoss:  0.15376119966943783\n",
      "\n",
      "\n",
      "========== step 0 itteration 1 ==========\n",
      "train LogLoss:  0.6931471805599454\n",
      "========== step 5 itteration 1 ==========\n",
      "train LogLoss:  0.18873199218674733\n",
      "========== step 10 itteration 1 ==========\n",
      "train LogLoss:  0.16468647139476117\n",
      "========== step 15 itteration 1 ==========\n",
      "train LogLoss:  0.1563548793178801\n",
      "========== step 20 itteration 1 ==========\n",
      "train LogLoss:  0.15240385181440652\n",
      "\n",
      "\n",
      "========== step 0 itteration 2 ==========\n",
      "train LogLoss:  0.6931471805599454\n",
      "========== step 5 itteration 2 ==========\n",
      "train LogLoss:  0.18942915627751747\n",
      "========== step 10 itteration 2 ==========\n",
      "train LogLoss:  0.1646080029535666\n",
      "========== step 15 itteration 2 ==========\n",
      "train LogLoss:  0.15577953351266716\n",
      "========== step 20 itteration 2 ==========\n",
      "train LogLoss:  0.15157880259779025\n",
      "\n",
      "\n",
      "========== step 0 itteration 3 ==========\n",
      "train LogLoss:  0.6931471805599454\n",
      "========== step 5 itteration 3 ==========\n",
      "train LogLoss:  0.19091039454263237\n",
      "========== step 10 itteration 3 ==========\n",
      "train LogLoss:  0.16641735392454576\n",
      "========== step 15 itteration 3 ==========\n",
      "train LogLoss:  0.1576825044680347\n",
      "========== step 20 itteration 3 ==========\n",
      "train LogLoss:  0.15345501664939984\n",
      "\n",
      "\n",
      "========== step 0 itteration 4 ==========\n",
      "train LogLoss:  0.6931471805599454\n",
      "========== step 5 itteration 4 ==========\n",
      "train LogLoss:  0.18378997587082746\n",
      "========== step 10 itteration 4 ==========\n",
      "train LogLoss:  0.15982709545154644\n",
      "========== step 15 itteration 4 ==========\n",
      "train LogLoss:  0.15164943370224068\n",
      "========== step 20 itteration 4 ==========\n",
      "train LogLoss:  0.14780820584818083\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Количество фолдов для обучения\n",
    "folds_quant=5\n",
    "\n",
    "msk= [randrange(folds_quant) for p in range(len(training_full))] \n",
    "model=[]\n",
    "\n",
    "for i in range(folds_quant):\n",
    "\n",
    "    vw = pyvw.vw( \n",
    "        loss_function='logistic',\n",
    "        link='logistic',\n",
    "        b=22,\n",
    "        q='aa',\n",
    "        cubic='aaa',\n",
    "        ngram=2,\n",
    "        skips=1,\n",
    "        l1=0.00001,\n",
    "        l2=0.00001,\n",
    "        f='vw.log.model',\n",
    "        learning_rate=0.4)\n",
    "\n",
    "    model.append(vw)\n",
    "\n",
    "    train=np.array(training_full)[list(np.array(msk) != i)]\n",
    "    test=np.array(training_full)[list(np.array(msk) == i)]\n",
    "    test_labels=np.array(y_train)[list(np.array(msk) == i)]\n",
    "\n",
    "    for iteration in range(25):\n",
    "        if iteration % 5 ==0:\n",
    "            train_predictions = [vw.predict(sample) for sample in training_full]\n",
    "            print(\"========== step {0} itteration {1} ==========\".format(iteration,i))\n",
    "            print(\"train LogLoss: \",log_loss(y_train, train_predictions))\n",
    "        for k in range(len(train)):\n",
    "            model[i].learn(train[k])\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Скорим тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('products_sentiment_test.tsv', sep='\\t', header = None,skiprows=1)\n",
    "df_test.columns = [\"id\", \"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text= df_test.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = test_text.apply(filter_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for text in test_text:\n",
    "    test.append(to_vw_format(str(text), 1)[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out=[]\n",
    "for i in range(len(model)):\n",
    "    test_out.append([model[i].predict(sample) for sample in test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Усредняем прогнозы 5 лучших моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame()\n",
    "results['id']=df_test.id\n",
    "results['y']=(np.array(test_out).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.950885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.258813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.735756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.685699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.301737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>495</td>\n",
       "      <td>0.514314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>0.625902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>497</td>\n",
       "      <td>0.113846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>0.505971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>499</td>\n",
       "      <td>0.678546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         y\n",
       "0      0  0.950885\n",
       "1      1  0.258813\n",
       "2      2  0.735756\n",
       "3      3  0.685699\n",
       "4      4  0.301737\n",
       "..   ...       ...\n",
       "495  495  0.514314\n",
       "496  496  0.625902\n",
       "497  497  0.113846\n",
       "498  498  0.505971\n",
       "499  499  0.678546\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
