{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\rusrob\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\MADE_env_py_36'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> import os\n",
    ">>> import sys\n",
    ">>> os.path.dirname(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vowpalwabbit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from vowpalwabbit import pyvw\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>assessment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 . take around 10,000 640x480 pictures .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  assessment\n",
       "0          2 . take around 10,000 640x480 pictures .           1\n",
       "1  i downloaded a trial version of computer assoc...           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/products_sentiment_train.tsv', sep='\\t', header = None)\n",
    "df_train.columns = [\"text\", \"assessment\"]\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, y_train = df_train.text, df_train.assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train, Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, train_labels, valid_labels  = \\\n",
    "    train_test_split(text_train, y_train, test_size=0.33, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. To VW format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "stemmer= PorterStemmer()\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\',\\\"()\\[\\]]\")\n",
    "# df_train[\"text_4gr\"] = df_train.text.apply(lambda x: \" \".join([word[:4] for word in REPLACE_NO_SPACE.sub(\"\", x).split(\" \")]))\n",
    "# df_train[\"text_stemmed\"] = df_train.text.apply(lambda x: \" \".join([stemmer.stem(word) for word in REPLACE_NO_SPACE.sub(\"\", x).split(\" \")]))\n",
    "# df_train[\"text_lemmatized\"] = df_train.text.apply(lambda x: \" \".join([lemmatizer.lemmatize(word, pos=\"v\") for word in REPLACE_NO_SPACE.sub(\"\", x).split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\rusrob/nltk_data'\n    - 'C:\\\\Users\\\\rusrob\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\MADE_env_py_36\\\\nltk_data'\n    - 'C:\\\\Users\\\\rusrob\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\MADE_env_py_36\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\rusrob\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\MADE_env_py_36\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\rusrob\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\MADE_env_py_36\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\MADE_env_py_36\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\rusrob/nltk_data'\n    - 'C:\\\\Users\\\\rusrob\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\MADE_env_py_36\\\\nltk_data'\n    - 'C:\\\\Users\\\\rusrob\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\MADE_env_py_36\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\rusrob\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\MADE_env_py_36\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\rusrob\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-e86467dabdf2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' |text '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"v\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mREPLACE_NO_SPACE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mdocument\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mto_vw_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-49-e86467dabdf2>\u001b[0m in \u001b[0;36mto_vw_format\u001b[1;34m(document, label)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#       return str(label or '') + ' |text ' + ' '.join(re.findall('\\w{3,}', document.lower())) + '\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#       return str(label or '') + ' |text ' + \" \".join([word[:4] for word in REPLACE_NO_SPACE.sub(\"\", document.lower()).split(\" \")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' |text '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"v\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mREPLACE_NO_SPACE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mdocument\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mto_vw_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-e86467dabdf2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#       return str(label or '') + ' |text ' + ' '.join(re.findall('\\w{3,}', document.lower())) + '\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#       return str(label or '') + ' |text ' + \" \".join([word[:4] for word in REPLACE_NO_SPACE.sub(\"\", document.lower()).split(\" \")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' |text '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"v\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mREPLACE_NO_SPACE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mdocument\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mto_vw_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\MADE_env_py_36\\lib\\site-packages\\nltk\\stem\\wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mlemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\MADE_env_py_36\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\MADE_env_py_36\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\MADE_env_py_36\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\MADE_env_py_36\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\rusrob/nltk_data'\n    - 'C:\\\\Users\\\\rusrob\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\MADE_env_py_36\\\\nltk_data'\n    - 'C:\\\\Users\\\\rusrob\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\MADE_env_py_36\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\rusrob\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\MADE_env_py_36\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\rusrob\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "def to_vw_format(document, label=None):\n",
    "#       return str(label or '') + ' |text ' + ' '.join(re.findall('\\w{3,}', document.lower())) + '\\n'\n",
    "#       return str(label or '') + ' |text ' + \" \".join([word[:4] for word in REPLACE_NO_SPACE.sub(\"\", document.lower()).split(\" \")\n",
    "      return str(label or '') + ' |text ' + \" \".join([lemmatizer.lemmatize(word, pos=\"v\") for word in REPLACE_NO_SPACE.sub(\"\",  document.lower()).split(\" \")]) + '\\n'\n",
    "    \n",
    "to_vw_format(str(text_train[1]), 1 if y_train[0] == 1 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('movie_reviews_train.vw', 'w') as vw_train_data:\n",
    "    for text, target in zip(train, train_labels):\n",
    "        vw_train_data.write(to_vw_format(str(text), 1 if target == 1 else -1))\n",
    "with open('movie_reviews_valid.vw', 'w') as vw_train_data:\n",
    "    for text, target in zip(valid, valid_labels):\n",
    "        vw_train_data.write(to_vw_format(str(text), 1 if target == 1 else -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples = []\n",
    "for text, target in zip(train, train_labels):\n",
    "    training_samples.append(to_vw_format(str(text), 1 if target == 1 else -1)[:-2])\n",
    "    \n",
    "test_samples = []\n",
    "for text, target in zip(valid, valid_labels):\n",
    "    test_samples.append(to_vw_format(str(text), 1 if target == 1 else -1)[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train\n",
    "https://www.analyticsvidhya.com/blog/2018/01/online-learning-guide-text-classification-vowpal-wabbit-vw/\n",
    "https://github.com/VowpalWabbit/vowpal_wabbit/blob/master/python/examples/poisson_regression.ipynb\n",
    "https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Command-line-arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-1 |text the onli problem i had wa a few compon didn t quit load correctli upon startup  but a reboot fix the problem'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_samples[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40 % 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== step 0 ==========\n",
      "train LogLoss:  0.6931471805599453\n",
      "test LogLoss:  0.6931471805599453\n",
      "========== step 10 ==========\n",
      "train LogLoss:  0.25639765429644185\n",
      "test LogLoss:  0.47669812689725316\n",
      "========== step 20 ==========\n",
      "train LogLoss:  0.20262984198327644\n",
      "test LogLoss:  0.47451386932606066\n",
      "========== step 30 ==========\n",
      "train LogLoss:  0.1734143014920438\n",
      "test LogLoss:  0.4779219409351343\n",
      "========== step 40 ==========\n",
      "train LogLoss:  0.15391360518455766\n",
      "test LogLoss:  0.4827244190629401\n",
      "========== step 50 ==========\n",
      "train LogLoss:  0.1395606742437928\n",
      "test LogLoss:  0.4879331097127721\n"
     ]
    }
   ],
   "source": [
    "# Train log-transform model\n",
    "\n",
    "# vw = pyvw.vw(\"-b 25 --loss_function logistic -l 0.2 --l2 0.00001 --link=logistic -f vw.log.model\")\n",
    "vw = pyvw.vw(\"-b 25 --loss_function logistic -l 0.2 --link=logistic -f vw.log.model\")\n",
    "# --holdout_off \n",
    "#  --readable_model vw.readable.log.model\n",
    "\n",
    "\n",
    "# Do hundred passes over the data and store the model in vw.log.model\n",
    "for iteration in range(51):\n",
    "    if iteration % 10 ==0:\n",
    "        train_predictions = [vw.predict(sample) for sample in training_samples]\n",
    "        test_predictions = [vw.predict(sample) for sample in test_samples]\n",
    "        print(\"========== step {0} ==========\".format(iteration))\n",
    "        print(\"train LogLoss: \",log_loss(train_labels, train_predictions))\n",
    "        print(\"test LogLoss: \",log_loss(valid_labels, test_predictions))\n",
    "    for i in range(len(training_samples)):\n",
    "            vw.learn(training_samples[i])\n",
    "vw.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Check on Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from the log-transform model\n",
    "vw = pyvw.vw(\"-i vw.log.model -t\")\n",
    "train_predictions = [vw.predict(sample) for sample in training_samples]\n",
    "test_predictions = [vw.predict(sample) for sample in test_samples]\n",
    "# Measure bias in the log-domain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_predictions, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Accuracy, LogLoss =======\n",
      "train LogLoss:  0.15407417824046024\n",
      "test LogLoss:  0.46686799050113675\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"======= Accuracy, LogLoss =======\")\n",
    "# print(\"train Accuracy: \",accuracy_score(y_train, train_predictions))\n",
    "# print(\"test Accuracy: \",accuracy_score(valid_labels, test_predictions))\n",
    "print(\"train LogLoss: \",log_loss(train_labels, train_predictions))\n",
    "print(\"test LogLoss: \",log_loss(valid_labels, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fitting a logistic regression for predicting the sentiment of a review\n",
    "!vw -d movie_reviews_train.vw --loss_function logistic -f movie_reviews_model.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vw = pyvw.vw(\"-d movie_reviews_train.vw --loss_function logistic -f movie_reviews_model.vw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "learn() missing 1 required positional argument: 'ec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-bad93ede1f12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: learn() missing 1 required positional argument: 'ec'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method hash_space of <vowpalwabbit.pyvw.vw object at 0x000000002D632650>>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hash_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<vowpalwabbit.pyvw.vw at 0x2d634d50>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pyvw.vw(\"-d movie_reviews_train.vw --loss_function logistic -f movie_reviews_model.vw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pyvw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.632030725479126"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from vowpalwabbit import pyvw\n",
    ">>> vw = pyvw.vw(quiet=False)\n",
    ">>> ex = vw.example('1 | a b c')\n",
    ">>> vw.learn(ex)\n",
    ">>> vw.predict(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "?vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
