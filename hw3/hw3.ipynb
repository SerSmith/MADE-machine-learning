{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda34323723de8944098ae5703be009b101",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd\n",
    " import numpy as np\n",
    " import sklearn \n",
    " from sklearn import datasets\n",
    " import torch\n",
    " import seaborn as sns\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,target=datasets.load_svmlight_file(\"data/train.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Предобработка исходных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_torch=torch.from_numpy(data.todense().astype(np.float32))\n",
    "target_torch=torch.from_numpy(target.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(target_torch)) < 0.8\n",
    "data_train=data_torch[msk]\n",
    "target_train=target_torch[msk]\n",
    "data_validate=data_torch[~msk]\n",
    "target_validate=target_torch[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Определение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher-level API:\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_size=20):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "      \n",
    "        self.layers = nn.Sequential(\n",
    "#             nn.Dropout(0.90) ,\n",
    "\n",
    "            nn.Linear(data_train.shape[1], hidden_size),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear( hidden_size, hidden_size),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear( hidden_size, 1),\n",
    "#            nn.Softmax()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm import trange\n",
    "\n",
    "# функция для итераций по минибатчам, из первого семинара\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(len(inputs))\n",
    "    for start_idx in trange(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "def plot_history(train_history, val_history, rang,  i, quantity_epoch,title='loss'):\n",
    "    if i%quantity_epoch==0:\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.plot(train_history)\n",
    "        plt.plot(np.arange(1, len(val_history) + 1) * (len(train_history)/len(val_history)),val_history, 'y+',markersize=15, markeredgewidth=2)\n",
    "        plt.xlabel(\"train steps\")\n",
    "        plt.title(\"Train Loss: {0} \\nVal Loss:  {1}\".format(np.round(train_history[-1],4), np.round(val_history[-1],4)))\n",
    "    #     plt.title(title + \"\\nloss at %i epoch\" %(rang+1)[-1])\n",
    "    #     plt.ylim([0,10**4])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(X_train, y_train, model, optimizer, batchsize=32, ModelType=\"first\"):\n",
    "    loss_log = []\n",
    "    model.train()\n",
    "\n",
    "    for x_batch, y_batch in iterate_minibatches(X_train, y_train, batchsize=batchsize, shuffle=True):\n",
    "        \n",
    "        data = torch.autograd.Variable(x_batch)\n",
    "        target = torch.autograd.Variable(y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "\n",
    "        loss = torch.sqrt((( output -  target) ** 2 ).mean())\n",
    "            \n",
    "#         ====================================================================================\n",
    "#         ====================================================================================\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "    return loss_log\n",
    "\n",
    "\n",
    "def test(model, X_val, y_val, ModelType=\"first\"):\n",
    "    loss_log = []\n",
    "    model.eval()  \n",
    "    tt = torch.autograd.Variable(X_val)\n",
    "    target = torch.autograd.Variable(y_val)\n",
    "    output = model.forward(tt)\n",
    " \n",
    "    loss = torch.sqrt((( output -  target) ** 2 ).mean())\n",
    "#         ====================================================================================\n",
    "#         ====================================================================================\n",
    "    \n",
    "    \n",
    "    loss_log.append(loss.item())\n",
    "\n",
    "    return loss_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "0%|          | 0/3 [00:00<?, ?it/s]"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "train_log = []\n",
    "val_log = []\n",
    "\n",
    "model = Net()\n",
    "# opt = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "# opt = torch.optim.RMSprop(model.parameters(), lr=0.01)\n",
    "batchsize = 100000\n",
    "\n",
    "rang = np.arange(400)\n",
    "for epoch in rang:\n",
    "    train_loss = train(X_train=data_train, y_train=target_train, model=model, optimizer=opt, batchsize=batchsize)\n",
    "    train_log.extend(train_loss)\n",
    "#     train_log.extend([np.array(train_loss).mean()])\n",
    "    \n",
    "    val_loss = np.mean(test(model=model, X_val=data_validate, y_val=target_validate))\n",
    "    val_log.append(val_loss)\n",
    "    # TODO: график train_loss vs train_steps с точками val_loss vs trained_steps\n",
    "    # use your plot_history()\n",
    "    plot_history(train_log, val_log, 1,epoch, 20)\n",
    "\n",
    "    # hint: train_log and val_log may contain data with different shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "378226\n"
    }
   ],
   "source": [
    "print(data_train.shape[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.shape"
   ]
  }
 ]
}